#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Sat Feb 13 23:16:00 2021@author: even"""import cv2import numpy as npimport sys, osimport globimport imutilsdef mathcingTemplate(img, template, method=cv2.TM_CCOEFF):    '''     Parameters    ----------    img : grayscale image    template : grayscale image    method: matching method, an integer,             'cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED'    Returns    -------    bounding box.    '''    img2 = img.copy()    template = cv2.Canny(template, 50, 200)    tH, tW = template.shape[:2]    cv2.imshow("Template", template)    found = None        # loop over the scales of the image    for scale in np.linspace(0.2, 1.0, 20)[::-1]:        resized = imutils.resize(img, width = int(img.shape[1] * scale))        r = img.shape[1] / float(resized.shape[1])        if resized.shape[0] < tH or resized.shape[1] < tW:            break                edged = cv2.Canny(resized, 50, 200)        cv2.imshow('frame', edged)        result = cv2.matchTemplate(edged, template, method)        (_, maxVal, _, maxLoc) = cv2.minMaxLoc(result)        		# if we have found a new maximum correlation value, then update		# the bookkeeping variable        if found is None or maxVal > found[0]:            found = (maxVal, maxLoc, r)             	# unpack the bookkeeping variable and compute the (x, y) coordinates 	# of the bounding box based on the resized ratio    (_, maxLoc, r) = found    (startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r))    (endX, endY) = (int((maxLoc[0] + tW) * r), int((maxLoc[1] + tH) * r))        return startX, startY, endX, endY    def my_skin_detect(src):    dst = np.zeros(np.shape(src)[:-1], dtype=np.uint8)        '''mask = np.logical_and.reduce((src[:,:,0] > 20, src[:,:,1] > 40, src[:,:,2] > 95,                                     src.max(axis=-1) - src.min(axis=-1) > 15,                                     abs(src[:,:,2] - src[:,:,1]) > 15,                                     src[:,:,2] > src[:,:,1], src[:,:,2] > src[:,:,0]))'''        mask = np.logical_and.reduce((src[:,:,2] > 95,src[:,:,1] > 40,src[:,:,0] > 20))    dst[mask] = 255    return dstif __name__ == "__main__":        # read templates from folder    templates = glob.glob("templates/*.png")        templates_gray = [ cv2.cvtColor(cv2.imread(template), cv2.COLOR_BGR2GRAY) for template in templates ]            cap = cv2.VideoCapture(0)        # if not successful, exit program    if not cap.isOpened():        print("Cannot open the video cam")        sys.exit()        # create a window called "MyVideo0"    cv2.namedWindow("MyVideo", cv2.WINDOW_AUTOSIZE)    cv2.namedWindow("MatchingFound", cv2.WINDOW_AUTOSIZE)        while(True):        # Capture frame-by-frame        ret, frame = cap.read()        if not ret:            print("Cannot read a frame from video stream")            break            cv2.imshow("MyVideo", frame)                # TODO:             # detect the hand,             # using skin detection or minus background        # hand_box = skin_detect(frame)                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)             # mathcingTemplate(gray, templates_gray[0])        startX, startY, endX, endY = mathcingTemplate(gray, templates_gray[0])        print(startX, startY, endX, endY)        # draw a bounding box around the detected result and display the image        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)        cv2.imshow("MatchingFound", frame)                        if cv2.waitKey(1) & 0xFF == ord('q'):            break        # When everything done, release the capture    cap.release()    cv2.destroyAllWindows()